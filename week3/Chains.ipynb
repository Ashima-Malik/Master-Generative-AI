{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In Langchain, chains are the core concept for building workflows within conversational AI agents. They essentially define the sequence of steps an agent takes to process information and generate a response.\n",
        "\n",
        "**What are Chains?**\n",
        "\n",
        "Chains are like recipes for your Langchain agent. They describe the step-by-step process the agent follows to complete a task.\n",
        "Each step in a chain can involve:\n",
        "Interacting with a Langchain tool (e.g., web search, summarization)\n",
        "Performing data manipulation or processing\n",
        "Making decisions based on the information gathered\n",
        "\n",
        "**Types of Chains:**\n",
        "\n",
        "There are different types of chains in Langchain, each suited for specific scenarios:\n",
        "\n",
        "**Simple Sequential Chain:** This is the most basic type of chain. It involves a linear sequence of steps, where the output from one step becomes the input for the next. It's ideal for simple tasks with a single input and a single output.\n",
        "\n",
        "**Transform Chain:**This type of chain allows you to apply transformations to the data at each step. It's useful when you need to manipulate or process information before feeding it to the next step.\n",
        "\n",
        "**Router Chain:** This chain is more complex and allows for conditional branching based on the information gathered at different points. It's suitable for tasks with multiple possible paths or outcomes depending on the user's input or retrieved information.\n",
        "\n",
        "**LLMChain (Large Language Model Chain):** This chain focuses on interactions with large language models (LLMs). It allows you to use LLMs for tasks like text generation, translation, or question answering within your workflow."
      ],
      "metadata": {
        "id": "indmmv7jNFUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain v/s Agents"
      ],
      "metadata": {
        "id": "B3tAknh7NVMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chains (Recipes):**\n",
        "\n",
        "**Function:** Chains define the workflow or sequence of steps an agent takes to process information and generate a response. Imagine a recipe that outlines the steps for cooking a dish.\n",
        "\n",
        "**Focus:** Chains focus on the specific actions involved in completing a task. They don't handle user interaction or manage the overall agent state.\n",
        "\n",
        "**Components:** Chains can involve interacting with Langchain tools (web search, summarization), manipulating data, and making decisions based on the information gathered.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "A chain for summarizing news articles might involve steps like:\n",
        "\n",
        "1. Use a web search tool to find relevant articles.\n",
        "2. Extract the text from the articles.\n",
        "3. Use a summarization tool to generate a summary of each article.\n",
        "4. Combine the summaries into a final response.\n",
        "\n",
        "Another chain for booking a restaurant reservation might involve:\n",
        "1. Use a dialog tool to gather user preferences (location, cuisine, etc.).\n",
        "2. Use a web search tool to find restaurants matching the criteria.\n",
        "3. Use an API integration tool to check availability at the chosen restaurant.\n",
        "4. Use a dialog tool to present options to the user and confirm the reservation."
      ],
      "metadata": {
        "id": "imqNpD2QNZXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agents (Chefs):**\n",
        "\n",
        "**Function:** Agents are the complete conversational AI entities that interact with users. They manage the overall conversation flow, interpret user input, and execute chains to generate responses. Imagine a chef following a recipe to prepare a dish for a customer.\n",
        "\n",
        "**Focus:** Agents handle user interaction and manage the agent's state throughout the conversation. They decide which chain to execute based on the user's input and the current context.\n",
        "\n",
        "**Components:** An agent typically incorporates one or more chains, along with functionalities for:\n",
        "1. Understanding user intent\n",
        "2. Managing conversation history\n",
        "3. Selecting the appropriate chain for the current situation\n",
        "4. Presenting the final response to the user\n",
        "\n",
        "Example: A restaurant reservation agent might:\n",
        "1. Ask the user about their preferences (location, cuisine, etc.) through dialog tools.\n",
        "2. Based on the user's input, choose and execute the \"booking restaurant reservation\" chain described earlier.\n",
        "3. Present the available options or confirmation details to the user based on the chain's output.\n",
        "\n",
        "**Analogy:**\n",
        "\n",
        "Think of a restaurant kitchen:\n",
        "\n",
        "Chains: Recipes outlining the steps for preparing specific dishes.\n",
        "Agent: The chef who follows the recipes, interacts with customers (takes orders), and manages the overall cooking process."
      ],
      "metadata": {
        "id": "z3P0bA-MN-NB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/docs/modules/chains"
      ],
      "metadata": {
        "id": "CZ6XGRxWORts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM Chain"
      ],
      "metadata": {
        "id": "3YT3iDpBPxHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\""
      ],
      "metadata": {
        "id": "IXk38dtVPoAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IbOc_IXP08a",
        "outputId": "b9ae8377-834a-4a59-e293-cd9a01bc8564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.27)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.30)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.23)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (2.6.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.30->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.30->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.30->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.30->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.30->langchain_community) (2.16.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdt1aw-0cJUy",
        "outputId": "010221ef-12f1-4901-9f32-db7a63b67543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.30)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.13.3)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (0.1.23)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.27->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.0.8 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "HcfJhUo7PqYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW5G_9KxQIVZ",
        "outputId": "13b94869-5df0-4de7-e1f3-9959800551c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(input_variables=['place'], template='Best place to visit in {place}')"
      ],
      "metadata": {
        "id": "MVG1yoO3QMEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "sD3fhS62QmPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run('USA'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r04Mx7N8Qqhv",
        "outputId": "c439a1c9-ca66-4d81-be91-8b09420ed5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "It is difficult to choose just one best place to visit in the USA as it depends on personal interests and preferences. However, some popular destinations that offer a variety of experiences include:\n",
            "\n",
            "1. New York City, New York: Known as the city that never sleeps, NYC is a bustling metropolis with iconic landmarks, world-class museums, Broadway shows, and diverse cuisine.\n",
            "\n",
            "2. Los Angeles, California: The entertainment capital of the world, LA is home to Hollywood, theme parks, beautiful beaches, and trendy neighborhoods.\n",
            "\n",
            "3. Grand Canyon, Arizona: One of the seven wonders of the world, the Grand Canyon is a breathtaking natural wonder that offers stunning views and opportunities for hiking and outdoor activities.\n",
            "\n",
            "4. Las Vegas, Nevada: Known for its vibrant nightlife, casinos, and extravagant shows, Las Vegas is a popular destination for entertainment and luxury.\n",
            "\n",
            "5. San Francisco, California: With its iconic Golden Gate Bridge, hilly streets, and diverse culture, San Francisco offers a unique blend of urban and natural beauty.\n",
            "\n",
            "6. Maui, Hawaii: The second largest island in Hawaii, Maui is known for its stunning beaches, waterfalls, and opportunities for outdoor activities like surfing and hiking.\n",
            "\n",
            "7. Orlando, Florida: Home to Walt Disney World and other theme parks, Orlando\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Sequential Chain"
      ],
      "metadata": {
        "id": "hZM12IKmRE5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "ifKASd-VRDSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "i0QSNKHvRKLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(input_variables=['cost'], template='Given a list of places, please estimate the cost to stay there {cost}')"
      ],
      "metadata": {
        "id": "lkF7zeARRcSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "FyTOzFRYR8lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = SimpleSequentialChain(chains=[place_chain, cost_chain], verbose=True)"
      ],
      "metadata": {
        "id": "_srI3Lg4SFl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = final_chain.run(\"USA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rs6lwI7SI1W",
        "outputId": "8f1b2995-825f-413c-e9b7-c7f95013c2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "The United States is a vast and diverse country with countless amazing destinations to visit. Depending on your interests and preferences, the best place to visit in the USA may vary. However, some popular and highly recommended destinations include:\n",
            "\n",
            "1. New York City, New York: Known as the \"Big Apple,\" New York City is a bustling metropolis filled with iconic landmarks, world-renowned museums, and diverse neighborhoods.\n",
            "\n",
            "2. Los Angeles, California: The \"City of Angels\" is a hub for entertainment, culture, and outdoor activities. Visit Hollywood, explore the beaches, or hike in the nearby mountains.\n",
            "\n",
            "3. San Francisco, California: This coastal city is famous for its hilly streets, iconic Golden Gate Bridge, and diverse food scene.\n",
            "\n",
            "4. Las Vegas, Nevada: Known as the \"Entertainment Capital of the World,\" Las Vegas is a popular destination for its vibrant nightlife, casinos, and shows.\n",
            "\n",
            "5. Miami, Florida: With its warm climate, beautiful beaches, and vibrant culture, Miami is a top destination for relaxation and fun.\n",
            "\n",
            "6. Grand Canyon, Arizona: A natural wonder of the world, the Grand Canyon offers breathtaking views and endless opportunities for outdoor recreation.\n",
            "\n",
            "7. Washington D.C.: The nation's capital is a must-visit for its\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m iconic monuments, museums, and historic landmarks.\n",
            "\n",
            "8. New Orleans, Louisiana: This vibrant city is known for its unique culture, delicious food, and lively music scene.\n",
            "\n",
            "Based on average hotel prices and cost of food and activities, the estimated cost for a week-long stay in each of these places would be:\n",
            "\n",
            "1. New York City, New York: $2,500-$3,500\n",
            "2. Los Angeles, California: $2,000-$3,000\n",
            "3. San Francisco, California: $2,500-$3,500\n",
            "4. Las Vegas, Nevada: $1,500-$2,500\n",
            "5. Miami, Florida: $2,000-$3,000\n",
            "6. Grand Canyon, Arizona: $1,500-$2,500\n",
            "7. Washington D.C.: $2,500-$3,500\n",
            "8. New Orleans, Louisiana: $2,000-$3,000\n",
            "\n",
            "Of course, these estimates can vary depending on the time of year, type of accommodations, and individual spending habits. It is always a good idea to research and plan ahead to get the best deals and stay within your budget.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarization"
      ],
      "metadata": {
        "id": "_gio3NXSbe26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Chain Name                 | Description                                                                                                  | Use Case                                                                                                                               | Parallelizable? |\n",
        "|----------------------------|--------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|-----------------|\n",
        "| StuffDocumentsChain        | Combines all documents into a single prompt for an LLM.                                                           | When the total content fits within the LLM's context window and you want all documents processed in a single call.                | No                |\n",
        "| ReduceDocumentsChain       | Iteratively reduces documents in chunks by feeding them to an LLM, then combining the results.                      | When you have a lot of documents exceeding the LLM's context window and want all documents included (can be batched for efficiency).  | Yes               |\n",
        "| MapReduceDocumentsChain    | Runs each document through an LLM first, then reduces the generated summaries using ReduceDocumentsChain.                    | Similar to ReduceDocumentsChain, but performs an initial individual LLM call on each document before reduction.                          | Yes               |\n",
        "| RefineDocumentsChain       | Generates an initial answer based on the first document, then iteratively refines it using LLMs on remaining documents.   | When you want to build an answer sequentially, refining based on previous outputs. Not suitable for parallelization.                  | No                |"
      ],
      "metadata": {
        "id": "TTt_w2n-amTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "loader = WebBaseLoader(\"https://www.texastribune.org/2024/03/08/texas-reservoir-formosa-chemical-expansion/\")\n",
        "docs = loader.load()\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\") #chain_type can be 'map_reduce' or 'refine' also\n",
        "\n",
        "chain.run(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "a_hxdA22cDqJ",
        "outputId": "86e670c0-5f2d-4715-9780-a10595468fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Texas Commission on Environmental Quality has approved water rights for a new reservoir to meet the growing needs of chemical plants, refineries, and other industries on the Gulf Coast. The reservoir, proposed on property owned by Formosa Plastics, will provide water for industrial plants looking to expand in the area. Formosa Plastics, a Taiwanese company, has faced legal challenges in Louisiana and is now pursuing expansion in Texas, which has raised concerns among environmental advocates due to the company's history of illegal pollution. The proposed reservoir will undergo a period of public comment before being adopted.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stuff"
      ],
      "metadata": {
        "id": "ZdHrkTyccvYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "NsVF1uYZcqzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt\n",
        "prompt_template = \"\"\"Write a detailed summary of the following:\n",
        "\"{text}\"\n",
        "DETAILED SUMMARY:\"\"\"\n",
        "prompt = PromptTemplate.from_template(prompt_template)"
      ],
      "metadata": {
        "id": "gVLyJotsc3eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM chain\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "cS8-jkCfc8GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define StuffDocumentsChain\n",
        "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")"
      ],
      "metadata": {
        "id": "8xJdXxZQc_FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()\n",
        "print(stuff_chain.run(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIaSKM2SdB4H",
        "outputId": "31ee7e9d-823b-4f2e-9355-1ca829f9e078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Texas Commission on Environmental Quality has approved water rights for a new reservoir to meet the growing needs of chemical plants, refineries, and other industries on the Gulf Coast. The Lavaca-Navidad River Authority (LNRA) has been authorized to divert up to 31 billion gallons per year from the Lavaca River to a reservoir proposed on property owned by Formosa Plastics. This comes as Formosa Plastics has faced legal challenges and opposition to its proposed chemical complex in Louisiana. The company has been fined for unpermitted discharges into air and water and has faced complaints about its environmental impact. Now, Formosa Plastics is looking to expand in Texas, and the proposed reservoir would provide the necessary water for this expansion. The LNRA currently supplies about 28 billion gallons of water each year from its only reservoir, Lake Texana, with no water left to spare. The new reservoir would add an additional 31 billion gallons per year from the Lavaca River. Formosa Plastics would have first rights to a portion of the water, but the details have not been negotiated. Environmental advocates are concerned about the company's expansion plans and its history of pollution. The draft water rights permit will undergo a period of public comment before being adopted, and if a hearing is requested, it could be several years before the project breaks ground.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Map-reduce"
      ],
      "metadata": {
        "id": "-exVtJrrdhw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Map\n",
        "map_template = \"\"\"The following is a set of documents\n",
        "{docs}\n",
        "Based on this list of docs, please identify the main themes\n",
        "Helpful Answer:\"\"\"\n",
        "map_prompt = PromptTemplate.from_template(map_template)\n",
        "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
      ],
      "metadata": {
        "id": "JNCumYchdqdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce\n",
        "reduce_template = \"\"\"The following is set of summaries:\n",
        "{docs}\n",
        "Take these and distill it into a final, consolidated summary of the main themes.\n",
        "Helpful Answer:\"\"\"\n",
        "reduce_prompt = PromptTemplate.from_template(reduce_template)"
      ],
      "metadata": {
        "id": "BToGOA7xqYc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chain\n",
        "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)"
      ],
      "metadata": {
        "id": "sYT6xoUHqikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
        ")\n",
        "\n",
        "# Combines and iteratively reduces the mapped documents\n",
        "reduce_documents_chain = ReduceDocumentsChain(\n",
        "    # This is final chain that is called.\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    # If documents exceed context for `StuffDocumentsChain`\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    # The maximum number of tokens to group documents into.\n",
        "    token_max=4000,\n",
        ")"
      ],
      "metadata": {
        "id": "sxX5rziXqwLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
        ")\n",
        "\n",
        "# Combines and iteratively reduces the mapped documents\n",
        "reduce_documents_chain = ReduceDocumentsChain(\n",
        "    # This is final chain that is called.\n",
        "    combine_documents_chain=combine_documents_chain,\n",
        "    # If documents exceed context for `StuffDocumentsChain`\n",
        "    collapse_documents_chain=combine_documents_chain,\n",
        "    # The maximum number of tokens to group documents into.\n",
        "    token_max=4000,\n",
        ")"
      ],
      "metadata": {
        "id": "8LtD5AZEryq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining documents by mapping a chain over them, then combining results\n",
        "map_reduce_chain = MapReduceDocumentsChain(\n",
        "    # Map chain\n",
        "    llm_chain=map_chain,\n",
        "    # Reduce chain\n",
        "    reduce_documents_chain=reduce_documents_chain,\n",
        "    # The variable name in the llm_chain to put the documents in\n",
        "    document_variable_name=\"docs\",\n",
        "    # Return the results of the map steps in the output\n",
        "    return_intermediate_steps=False,\n",
        ")\n",
        "\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "split_docs = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "fnb893PDsCO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(map_reduce_chain.run(split_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYoecqOSr1fz",
        "outputId": "86c73215-e586-4046-d84f-edbfff42033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The main themes of the documents include environmental concerns and opposition to industrial growth, water rights and reservoir development for industry needs, Formosa Plastics' expansion plans and regulatory challenges, and the impact of the fracking boom on downstream industrial buildout. Additionally, there is a focus on community engagement, Texas pride, social media presence, and networking opportunities through platforms like the Facebook Group \"This Is Your Texas.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refine"
      ],
      "metadata": {
        "id": "_jl2CN6psaKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
        "chain.run(split_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Jg0tSZNVsdO0",
        "outputId": "dbb2d442-b038-4ba2-d0d7-a009f73aa108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Texas regulators have approved water rights for a new reservoir to meet the needs of chemical plants and refineries on the Gulf Coast, with Formosa Plastics looking to expand around Lavaca Bay after facing challenges in Louisiana. The proposed reservoir will provide water for industrial plants in the area, fueling petrochemical expansion on the Texas coast. The Lavaca-Navidad River Authority (LNRA) is seeking water permits to supply water to Formosa Plastics and other industrial customers in the region, with Formosa's expansion plans in Texas following legal challenges in Louisiana. Formosa has a history of pollution violations, including a recent settlement over plastic dumping in Lavaca Bay. Additionally, Formosa has reported violations of its air pollution permits, releasing harmful chemicals at rates far exceeding permitted levels. Despite ongoing pollution issues, Formosa is pushing for expansion in Texas. The draft water rights permit will undergo a public comment period, potentially delaying the project for several years. Join our Facebook Group, This Is Your Texas.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bsh_RwsYshXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}